{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " dict_keys(['postorder_node_indices', 'child_indices', 'preorder_indices', 'preorder_node_indices', 'sibling_indices', 'parent_indices']))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import treeflow.tree_processing\n",
    "reload(treeflow.tree_processing)\n",
    "import treeflow.sequences\n",
    "newick_file = '../data/analysis-tree.nwk'\n",
    "fasta_file = '../data/sim-seq.fasta'\n",
    "\n",
    "tree, taxon_names = treeflow.tree_processing.parse_newick(newick_file)\n",
    "topology = treeflow.tree_processing.update_topology_dict(tree['topology'])\n",
    "taxon_count = len(taxon_names)\n",
    "taxon_count, topology.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree': {'topology': {'parent_indices': <tf.Tensor: shape=(198,), dtype=int64, numpy=\n",
       "   array([100, 100, 101, 102, 103, 104, 105, 106, 106, 107, 108, 109, 111,\n",
       "          111, 112, 112, 115, 115, 116, 117, 118, 118, 120, 120, 121, 122,\n",
       "          122, 123, 125, 125, 127, 127, 128, 128, 129, 129, 130, 132, 132,\n",
       "          133, 136, 140, 140, 141, 141, 142, 144, 145, 146, 146, 147, 148,\n",
       "          148, 151, 151, 153, 153, 154, 156, 156, 157, 158, 158, 159, 161,\n",
       "          161, 162, 164, 165, 166, 167, 167, 168, 169, 170, 173, 174, 174,\n",
       "          175, 176, 177, 177, 179, 181, 181, 183, 183, 184, 185, 185, 186,\n",
       "          186, 187, 188, 189, 190, 192, 192, 193, 194, 101, 102, 103, 104,\n",
       "          105, 110, 107, 108, 109, 110, 114, 113, 113, 114, 139, 116, 117,\n",
       "          119, 119, 138, 121, 124, 123, 124, 126, 126, 137, 135, 131, 130,\n",
       "          131, 134, 133, 134, 135, 136, 137, 138, 139, 198, 143, 142, 143,\n",
       "          144, 145, 150, 147, 149, 149, 150, 152, 152, 155, 154, 155, 172,\n",
       "          157, 160, 159, 160, 163, 162, 163, 164, 165, 166, 171, 168, 169,\n",
       "          170, 171, 172, 173, 180, 175, 176, 178, 178, 179, 180, 182, 182,\n",
       "          197, 184, 196, 191, 187, 188, 189, 190, 191, 195, 193, 194, 195,\n",
       "          196, 197, 198])>},\n",
       "  'heights': <tf.Tensor: shape=(199,), dtype=float32, numpy=\n",
       "  array([9.99999975e-06, 9.99999975e-06, 9.99999975e-06, 9.99999975e-06,\n",
       "         9.99999975e-06, 9.99999975e-06, 9.99999975e-06, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 9.99999975e-06, 9.99999975e-06,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 9.99999975e-06, 9.99999975e-06,\n",
       "         9.99999975e-06, 9.99999975e-06, 9.99999975e-06, 1.99999995e-05,\n",
       "         9.99999975e-06, 9.99999975e-06, 1.99999995e-05, 1.99999995e-05,\n",
       "         9.99999975e-06, 9.99999975e-06, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         9.99999975e-06, 9.99999975e-06, 9.99999975e-06, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         9.99999975e-06, 9.99999975e-06, 9.99999975e-06, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 9.99999975e-06, 9.99999975e-06, 9.99999975e-06,\n",
       "         9.99999975e-06, 9.99999975e-06, 9.99999975e-06, 9.99999975e-06,\n",
       "         9.99999975e-06, 9.99999975e-06, 9.99999975e-06, 9.99999975e-06,\n",
       "         9.99999975e-06, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 2.99999992e-05, 1.99999995e-05, 9.99999975e-06,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         9.99999975e-06, 9.99999975e-06, 1.99999995e-05, 9.99999975e-06,\n",
       "         9.99999975e-06, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.99999995e-05, 1.99999995e-05, 1.99999995e-05, 1.99999995e-05,\n",
       "         1.93536699e-01, 2.10373327e-01, 2.12067768e-01, 2.15825200e-01,\n",
       "         4.37260449e-01, 6.10825658e-01, 1.52070094e-02, 1.67233236e-02,\n",
       "         3.08802072e-02, 3.89016457e-02, 7.16703534e-01, 3.12653840e-01,\n",
       "         5.31798303e-02, 3.19904208e-01, 9.68257427e-01, 1.61114372e-02,\n",
       "         2.32458990e-02, 2.92273890e-02, 1.37226209e-01, 2.81419098e-01,\n",
       "         1.68420654e-02, 5.35611771e-02, 1.85029567e-04, 1.63867662e-03,\n",
       "         5.51725887e-02, 2.04754621e-02, 5.59690632e-02, 1.63831055e-01,\n",
       "         2.03643709e-01, 2.28392966e-02, 8.66209716e-02, 2.11123839e-01,\n",
       "         1.88245089e-04, 1.02144794e-03, 3.03861231e-01, 3.93139511e-01,\n",
       "         3.93622994e-01, 4.03616548e-01, 6.19540095e-01, 1.02730322e+00,\n",
       "         2.00017210e-04, 4.11418825e-03, 5.30750863e-03, 6.82434067e-03,\n",
       "         8.37857090e-03, 8.41827504e-03, 1.86481207e-04, 4.14461596e-04,\n",
       "         1.20953599e-03, 1.12515641e-02, 2.19118092e-02, 1.30973675e-03,\n",
       "         6.75217435e-02, 3.66403610e-02, 5.48626557e-02, 1.14107497e-01,\n",
       "         1.64544135e-02, 2.19229087e-02, 4.29935195e-03, 4.68148710e-03,\n",
       "         2.69975271e-02, 9.35435703e-04, 1.96781522e-03, 2.81927027e-02,\n",
       "         2.89330687e-02, 2.91376952e-02, 6.46425486e-02, 1.06176930e-02,\n",
       "         1.57729387e-02, 3.86866145e-02, 7.45825469e-02, 8.45430642e-02,\n",
       "         1.77034751e-01, 1.78817332e-01, 8.59285792e-05, 9.29490197e-05,\n",
       "         2.14928732e-04, 9.58269276e-03, 2.99067833e-02, 5.62861450e-02,\n",
       "         2.68620580e-01, 5.01858711e-01, 6.71581268e-01, 1.62564218e-02,\n",
       "         2.69097276e-02, 6.72696605e-02, 3.38819101e-02, 3.47663909e-02,\n",
       "         5.61569184e-02, 6.09008372e-02, 8.89585838e-02, 1.13552354e-01,\n",
       "         2.71316823e-02, 2.88702380e-02, 3.27439606e-02, 2.67835557e-01,\n",
       "         5.87038040e-01, 7.13446796e-01, 1.41846740e+00], dtype=float32)>},\n",
       " 'pop_size': <tf.Tensor: shape=(), dtype=float32, numpy=2.2759485>,\n",
       " 'kappa': <tf.Tensor: shape=(), dtype=float32, numpy=2.0477378>,\n",
       " 'frequencies': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.21237446, 0.14285456, 0.2352964 , 0.4094746 ], dtype=float32)>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import treeflow.tree_transform\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "import treeflow.tf_util\n",
    "reload(treeflow.tf_util)\n",
    "\n",
    "reload(treeflow.tree_transform)\n",
    "\n",
    "anchor_heights = treeflow.tree_processing.get_node_anchor_heights(tree['heights'], topology['postorder_node_indices'], topology['child_indices'])\n",
    "anchor_heights = tf.convert_to_tensor(anchor_heights, dtype=tf.float32)\n",
    "tree_chain = treeflow.tree_transform.TreeChain(\n",
    "    topology['parent_indices'][taxon_count:] - taxon_count,\n",
    "    topology['preorder_node_indices'][1:] - taxon_count,\n",
    "    anchor_heights=anchor_heights)\n",
    "init_heights = tf.convert_to_tensor(tree['heights'][taxon_count:], dtype=tf.float32)\n",
    "init_heights_trans = tree_chain.inverse(init_heights)\n",
    "leaf_heights = tf.convert_to_tensor(tree['heights'][:taxon_count], dtype=tf.float32)\n",
    "\n",
    "height_dist = tfd.Blockwise([\n",
    "    tfd.Independent(tfd.Deterministic(leaf_heights), reinterpreted_batch_ndims=1),\n",
    "    tfd.TransformedDistribution(\n",
    "        distribution=tfd.Independent(tfd.Normal(\n",
    "            loc=tf.Variable(init_heights_trans, name='q_tree_loc'),\n",
    "            scale=tfp.util.DeferredTensor(tf.Variable(tf.ones_like(init_heights_trans), name='q_tree_scale'), tf.nn.softplus)\n",
    "        ), reinterpreted_batch_ndims=1),\n",
    "        bijector=tree_chain\n",
    "    )\n",
    "])\n",
    "\n",
    "q = tfd.JointDistributionNamed(dict(\n",
    "    tree=treeflow.tree_transform.FixedTopologyDistribution(\n",
    "        height_distribution=height_dist,\n",
    "        topology=tree['topology']\n",
    "    ),\n",
    "    kappa=tfd.LogNormal(\n",
    "        loc=tf.Variable(0.0, name='q_kappa_loc'),\n",
    "        scale=tfp.util.DeferredTensor(tf.Variable(1.0, name='q_kappa_scale'), tf.nn.softplus)\n",
    "    ),\n",
    "    pop_size=tfd.LogNormal(\n",
    "        loc=tf.Variable(0.0, name='q_pop_size_loc'),\n",
    "        scale=tfp.util.DeferredTensor(tf.Variable(1.0, name='q_pop_size_scale'), tf.nn.softplus)\n",
    "    ),\n",
    "    frequencies=tfd.Dirichlet(concentration=tfp.util.DeferredTensor(tf.Variable([4.0, 4.0, 4.0, 4.0], name='q_frequencies_concentration'), tf.nn.softplus))\n",
    "))\n",
    "#[(var.name, var.shape) for var in q.trainable_variables]\n",
    "q.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "## Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pop_size': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-8.627281 , -2.3740983], dtype=float32)>,\n",
       " 'tree': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-329.62326 , -105.402954], dtype=float32)>,\n",
       " 'kappa': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.5493054, -0.5087566], dtype=float32)>,\n",
       " 'frequencies': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2.8152523, 1.9390144], dtype=float32)>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import treeflow.coalescent\n",
    "reload(treeflow.coalescent)\n",
    "\n",
    "sampling_times = tf.convert_to_tensor(tree['heights'][:taxon_count], dtype=tf.float32)\n",
    "\n",
    "prior = tfd.JointDistributionNamed(dict(\n",
    "    frequencies=tfd.Dirichlet(concentration=[4,4,4,4]),\n",
    "    kappa=tfd.LogNormal(loc=0, scale=1),\n",
    "    pop_size=tfd.LogNormal(loc=0, scale=1),\n",
    "    #site_alpha=tfd.LogNormal(loc=0, scale=1),\n",
    "    #clock_rate=tfd.LogNormal(loc=0, scale=1),\n",
    "    tree=lambda pop_size: treeflow.coalescent.ConstantCoalescent(pop_size=pop_size, sampling_times=sampling_times)\n",
    "))\n",
    "\n",
    "prior.log_prob_parts(q.sample(sample_shape=[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/chris/git/treeflow/treeflow/coalescent.py:75: UserWarning: Dummy sampling\n",
      "  warnings.warn('Dummy sampling')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 528.4222 ,  595.3603 ,  804.103  ,  532.0404 ,  599.3718 ,\n",
       "        534.39667,  665.00134,  762.3739 , 3053.35   ,  713.8525 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp.vi.fit_surrogate_posterior(prior.log_prob, q, tf.optimizers.Adam(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2,198] vs. [1,199] [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-607146330664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mq_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kappa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frequencies'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-607146330664>\u001b[0m in \u001b[0;36mlog_likelihood\u001b[0;34m(tree, kappa, frequencies)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcategory_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcategory_rates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_rates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbranch_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtreeflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_branch_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mfrequencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/chris/git/treeflow/treeflow/sequences.py\u001b[0m in \u001b[0;36mget_branch_lengths\u001b[0;34m(tree)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_branch_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mheights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'heights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topology'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_indices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mheights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_conditioned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/libsbn/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/libsbn/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  10134\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10135\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10136\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10137\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10138\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m~/miniconda3/envs/libsbn/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6623\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6624\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6625\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6626\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/libsbn/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,198] vs. [1,199] [Op:Sub]"
     ]
    }
   ],
   "source": [
    "import treeflow.sequences\n",
    "reload(treeflow.sequences)\n",
    "import treeflow.substitution_model\n",
    "\n",
    "subst_model = treeflow.substitution_model.HKY()\n",
    "category_weights = tf.ones(1)\n",
    "category_rates = tf.ones(1)\n",
    "\n",
    "alignment = treeflow.sequences.get_encoded_sequences(fasta_file, taxon_names)\n",
    "log_prob_conditioned = treeflow.sequences.log_prob_conditioned(alignment, tree['topology'], 1)\n",
    "                 \n",
    "def log_likelihood(tree, kappa, frequencies):  \n",
    "    return log_prob_conditioned(\n",
    "        subst_model=subst_model,\n",
    "        category_weights=category_weights,\n",
    "        category_rates=category_rates,\n",
    "        branch_lengths=treeflow.sequences.get_branch_lengths(tree, ),\n",
    "        frequencies=frequencies,\n",
    "        kappa=kappa\n",
    "    )\n",
    "                 \n",
    "q_sample = q.sample(sample_shape=[2])\n",
    "                 \n",
    "log_likelihood(q_sample['tree'], q_sample['kappa'], q_sample['frequencies'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
