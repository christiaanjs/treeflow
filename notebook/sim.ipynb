{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christiaanjs/miniconda3/envs/libsbn/lib/python3.7/site-packages/ipykernel_launcher.py:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'beast_jar': 'lib/feast.jar',\n",
       "  'burn_in': 0.1,\n",
       "  'chain_length': 1000000,\n",
       "  'estimate_clock_rate': False,\n",
       "  'estimate_topology': False,\n",
       "  'frequencies': [0.24, 0.26, 0.26, 0.24],\n",
       "  'inference': 'mean_field',\n",
       "  'init_values': {'clock_rate': 1.0, 'kappa': 2.0, 'pop_size': 10},\n",
       "  'kappa': 2.0,\n",
       "  'log_every': 100,\n",
       "  'lsd_executable': 'lsd',\n",
       "  'mutation_rate': 0.01,\n",
       "  'n_eval_samples': 200,\n",
       "  'n_iter': 40000,\n",
       "  'n_runs': 10,\n",
       "  'n_taxa': 5,\n",
       "  'n_trace_samples': 1000,\n",
       "  'nuts_draws': 10000,\n",
       "  'nuts_tune': 100,\n",
       "  'out_dir': 'out/0',\n",
       "  'prior_params': {'clock_rate': {'m': 1.0, 's': 1.25},\n",
       "   'kappa': {'m': 1.0, 's': 1.25},\n",
       "   'pop_size': {'m': 2.0, 's': 0.1}},\n",
       "  'rate_sd': None,\n",
       "  'relaxed_clock': False,\n",
       "  'sampling_window': 0,\n",
       "  'seed': 1,\n",
       "  'sequence_length': 1000},\n",
       " 'date_trait_string': 'A=0.0,B=0.0,C=0.0,D=0.0,E=0.0',\n",
       " 'newick_string': '((B:0.910978734132923,E:0.910978734132923):10.536638972692,((D:1.9219086332202198,C:1.9219086332202198):2.438807589499588,A:4.360716222719808):7.086901484105114):0.0;\\n',\n",
       " 'pop_size': 6.6189588375063755}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../data/run_summary.yaml') as f:\n",
    "    run_summary = yaml.load(f)\n",
    "    \n",
    "run_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import treeflow.coalescent\n",
    "tfd = tfp.distributions\n",
    "\n",
    "pop_size = tf.convert_to_tensor(run_summary['pop_size'])\n",
    "taxon_count = run_summary['config']['n_taxa']\n",
    "sampling_times = tf.zeros(taxon_count)\n",
    "prior = tfd.JointDistributionNamed(dict(\n",
    "    tree=treeflow.coalescent.ConstantCoalescent(taxon_count=taxon_count, pop_size=pop_size, sampling_times=sampling_times)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-2639.814>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import treeflow.substitution_model\n",
    "import treeflow.sequences\n",
    "import treeflow.tree_processing\n",
    "\n",
    "from importlib import reload\n",
    "reload(treeflow.sequences)\n",
    "\n",
    "fasta_file = '../data/sim-seq.fasta'\n",
    "newick_file = '../data/sim-seq.newick'\n",
    "subst_model = treeflow.substitution_model.HKY()\n",
    "category_weights = tf.ones(1)\n",
    "category_rates = tf.ones(1)\n",
    "mutation_rate = tf.convert_to_tensor(run_summary['config']['mutation_rate'], dtype=tf.float32)\n",
    "kappa = tf.convert_to_tensor(run_summary['config']['kappa'], dtype=tf.float32)\n",
    "frequencies = tf.convert_to_tensor(run_summary['config']['frequencies'], dtype=tf.float32)\n",
    "tree, taxon_names = treeflow.tree_processing.parse_newick(newick_file)\n",
    "tree_ = treeflow.tree_processing.tree_to_tensor(tree)\n",
    "alignment = treeflow.sequences.get_encoded_sequences(fasta_file, taxon_names)\n",
    "log_prob_conditioned = treeflow.sequences.log_prob_conditioned_branch_only(\n",
    "    alignment,\n",
    "    tree['topology'],\n",
    "    1,\n",
    "    subst_model,\n",
    "    category_weights,\n",
    "    category_rates,\n",
    "    frequencies,\n",
    "    kappa=kappa\n",
    ")\n",
    "log_prob = lambda **z: (prior.log_prob(z) + log_prob_conditioned(branch_lengths=treeflow.sequences.get_branch_lengths(z['tree']) * mutation_rate))\n",
    "log_prob(tree=tree_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-3131.0784>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import treeflow.tree_transform\n",
    "\n",
    "topology = treeflow.tree_processing.update_topology_dict(tree['topology'])\n",
    "anchor_heights = treeflow.tree_processing.get_node_anchor_heights(tree['heights'], topology['postorder_node_indices'], topology['child_indices'])\n",
    "anchor_heights = tf.convert_to_tensor(anchor_heights, dtype=tf.float32)\n",
    "\n",
    "node_parent_indices = topology['parent_indices'][taxon_count:] - taxon_count\n",
    "\n",
    "tree_chain = treeflow.tree_transform.TreeChain(\n",
    "    node_parent_indices,\n",
    "    topology['preorder_node_indices'][1:] - taxon_count,\n",
    "    anchor_heights=anchor_heights)\n",
    "init_heights = tf.convert_to_tensor(tree['heights'][taxon_count:], dtype=tf.float32)\n",
    "init_heights_trans = tree_chain.inverse(init_heights)\n",
    "leaf_heights = tf.convert_to_tensor(tree['heights'][:taxon_count], dtype=tf.float32)\n",
    "\n",
    "height_dist = tfd.Blockwise([\n",
    "    tfd.Independent(tfd.Deterministic(leaf_heights), reinterpreted_batch_ndims=1),\n",
    "    tfd.TransformedDistribution(\n",
    "        distribution=tfd.Independent(tfd.Normal(\n",
    "            loc=tf.Variable(init_heights_trans, name='q_tree_loc'),\n",
    "            scale=tfp.util.DeferredTensor(tf.Variable(tf.ones_like(init_heights_trans), name='q_tree_scale'), tf.nn.softplus)\n",
    "        ), reinterpreted_batch_ndims=1),\n",
    "        bijector=tree_chain\n",
    "    )\n",
    "])\n",
    "q = tfd.JointDistributionNamed(dict(\n",
    "        tree=treeflow.tree_transform.FixedTopologyDistribution(\n",
    "            height_distribution=height_dist,\n",
    "            topology=tree['topology']\n",
    ")))\n",
    "log_prob(**q.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import treeflow.vi\n",
    "\n",
    "res = treeflow.vi.fit_surrogate_posterior(log_prob, q, tf.optimizers.Adam(learning_rate=0.01), 10000, iter=lambda x: tqdm(range(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(res['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res['vars']['q_tree_loc:0']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res['vars']['q_tree_scale:0']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clades = [[] for _ in range(taxon_count - 1)]\n",
    "for i in topology['postorder_node_indices']:\n",
    "    for child_index in topology['child_indices'][i]:\n",
    "        clades[i - taxon_count] += clades[child_index - taxon_count] if child_index >= taxon_count else taxon_names[child_index]\n",
    "\n",
    "clade_names = [''.join(sorted(names)) for names in clades]\n",
    "clade_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd\n",
    "\n",
    "q_samples = q.sample(10000)\n",
    "tf_data = pd.DataFrame(q_samples['tree']['heights'][:, taxon_count:].numpy(), columns=clade_names)\n",
    "tf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dendropy\n",
    "\n",
    "def get_node_heights(tree):\n",
    "    tree.calc_node_ages()\n",
    "    return { ''.join(sorted([leaf.taxon.label for leaf in node.leaf_iter()])): node.age for node in tree.preorder_node_iter() if not node.is_leaf() }\n",
    "\n",
    "beast_log = dendropy.TreeList.get(path='beast-log-fixed.trees', schema='nexus')\n",
    "burn_in = 0.1\n",
    "beast_log = beast_log[int(len(beast_log) * burn_in):]\n",
    "beast_samples = [get_node_heights(tree) for tree in tqdm(beast_log)]\n",
    "beast_data = pd.DataFrame(beast_samples)\n",
    "beast_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat(dict(beast=beast_data, variational=tf_data), sort=True, names=['method']).reset_index(level='method')\n",
    "g = seaborn.PairGrid(all_data, hue=\"method\", hue_kws={\"cmap\": [\"Blues\", \"Reds\"] }, palette=['blue', 'red'])\n",
    "g = g.map_diag(seaborn.kdeplot)\n",
    "g = g.map_upper(plt.scatter, alpha=0.01)\n",
    "g = g.map_lower(seaborn.kdeplot)\n",
    "g = g.add_legend()\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Tree heights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = seaborn.PairGrid(beast_data[clade_names])\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "g = g.map_diag(seaborn.kdeplot)\n",
    "g = g.map_upper(plt.scatter, alpha=0.01)\n",
    "g = g.map_lower(seaborn.kdeplot)\n",
    "g = g.map_upper(corrfunc)\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Tree heights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "beast_values = tf.convert_to_tensor(beast_data[clade_names].values, dtype=tf.float32)\n",
    "beast_values_trans = tree_chain.inverse(beast_values)\n",
    "beast_data_trans = pd.DataFrame(beast_values_trans.numpy(), columns=clade_names)\n",
    "g = seaborn.PairGrid(beast_data_trans)\n",
    "g = g.map_upper(plt.scatter, alpha=0.01)\n",
    "g = g.map_diag(seaborn.kdeplot)\n",
    "g = g.map_lower(seaborn.kdeplot)\n",
    "g.map_upper(corrfunc)\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Unconstrained values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximation with correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-2693.0183>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import treeflow.tree_transform\n",
    "\n",
    "reload(treeflow.tree_transform)\n",
    "\n",
    "beta = tf.Variable(tf.zeros(taxon_count - 2), name='q2_beta')\n",
    "node_corr = treeflow.tree_transform.ParentCorrelation(node_parent_indices, beta)\n",
    "tree_chain2 = tfp.bijectors.Chain([tree_chain, node_corr])\n",
    "\n",
    "height_dist2 = tfd.Blockwise([\n",
    "    tfd.Independent(tfd.Deterministic(leaf_heights), reinterpreted_batch_ndims=1),\n",
    "    tfd.TransformedDistribution(\n",
    "        distribution=tfd.Independent(tfd.Normal(\n",
    "            loc=tf.Variable(init_heights_trans, name='q2_tree_loc'),\n",
    "            scale=tfp.util.DeferredTensor(tf.Variable(tf.ones_like(init_heights_trans), name='q2_tree_scale'), tf.nn.softplus)\n",
    "        ), reinterpreted_batch_ndims=1),\n",
    "        bijector=tree_chain2\n",
    "    )\n",
    "])\n",
    "q2 = tfd.JointDistributionNamed(dict(\n",
    "        tree=treeflow.tree_transform.FixedTopologyDistribution(\n",
    "            height_distribution=height_dist2,\n",
    "            topology=tree['topology']\n",
    ")))\n",
    "log_prob(**q2.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'q2_beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'q2_tree_loc:0' shape=(4,) dtype=float32, numpy=array([-2.6026895 , -0.32975328, -0.5029515 ,  2.3174736 ], dtype=float32)>,\n",
       " <tf.Variable 'q2_tree_scale:0' shape=(4,) dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0a1f50f88d43edb1005a254524ce9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import treeflow.vi\n",
    "from tqdm.notebook import tqdm\n",
    "res = treeflow.vi.fit_surrogate_posterior(log_prob, q2, tf.optimizers.Adam(learning_rate=0.01), 10000, iter=lambda x: tqdm(range(x)), trainable_variables=q2.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd\n",
    "\n",
    "q2_samples = q.sample(10000)\n",
    "tf_data = pd.DataFrame(q2_samples['tree']['heights'][:, taxon_count:].numpy(), columns=clade_names)\n",
    "tf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat(dict(beast=beast_data, variational=tf_data), sort=True, names=['method']).reset_index(level='method')\n",
    "g = seaborn.PairGrid(all_data, hue=\"method\", hue_kws={\"cmap\": [\"Blues\", \"Reds\"] }, palette=['blue', 'red'])\n",
    "g = g.map_diag(seaborn.kdeplot)\n",
    "g = g.map_upper(plt.scatter, alpha=0.01)\n",
    "g = g.map_lower(seaborn.kdeplot)\n",
    "g = g.add_legend()\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Tree heights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
